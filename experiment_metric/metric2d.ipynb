{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metric (Lasot and vot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Success and Precsion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from typing import List, Iterable, Tuple, Any\n",
    "import itertools\n",
    "import sys\n",
    "sys.path.append('/home/lz/anaconda3/envs/nbconda/lib/python3.9/site-packages/vot/')\n",
    "from attributee import Float, Integer, Boolean, Include\n",
    "import os\n",
    "from vot.tracker import Tracker\n",
    "from vot.dataset import Sequence\n",
    "from vot.region import Region, RegionType, calculate_overlaps\n",
    "from vot.experiment import Experiment\n",
    "from vot.experiment.multirun import UnsupervisedExperiment\n",
    "from vot.analysis import SequenceAggregator, Analysis, SeparableAnalysis, \\\n",
    "    MissingResultsException, Measure, Sorting, Curve, Plot, SequenceAggregator, \\\n",
    "    Axes, analysis_registry\n",
    "from vot.utilities.data import Grid\n",
    "import numpy as np\n",
    "from shapely.geometry import Polygon\n",
    "\n",
    "import logging\n",
    "import scipy\n",
    "import scipy.io\n",
    "log_path = os.path.join(os.getcwd(), 'my.log')\n",
    "logging.basicConfig(filename=log_path, level=logging.DEBUG, filemode='w', format='%(levelname)s:%(asctime)s:%(message)s', datefmt='%Y-%d-%m %H:%M:%S')\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def estimateIOU(box_a, box_b):\n",
    "    if str(box_b[0]) == 'nan':\n",
    "        return 0\n",
    "    areaA = box_a[2] * box_a[3]\n",
    "    areaB = box_b[2] * box_b[3]\n",
    "\n",
    "    area_sum = areaA + areaB\n",
    "    max_a_x = box_a[0] + box_a[2]\n",
    "    max_a_y = box_a[1] + box_a[3]\n",
    "\n",
    "    max_b_x = box_b[0] + box_b[2]\n",
    "    max_b_y = box_b[1] + box_b[3]\n",
    "\n",
    "    inter_x_max = min(max_a_x, max_b_x)\n",
    "    inter_y_max = min(max_a_y, max_b_y)\n",
    "    inter_x_min = max(box_a[0], box_b[0])\n",
    "    inter_y_min = max(box_a[1], box_b[1])\n",
    "    inter_w = inter_x_max - inter_x_min\n",
    "    inter_h = inter_y_max - inter_y_min\n",
    "    if inter_w<=0 or inter_h<=0:\n",
    "        inter_area = 0 \n",
    "    else:\n",
    "        inter_area = inter_w * inter_h\n",
    "\n",
    "    overlap = inter_area  / (area_sum - inter_area)\n",
    "    return overlap\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Success(object):\n",
    "    \"\"\"Computes and stores the Success\"\"\"\n",
    "\n",
    "    def __init__(self, n=21, max_overlap=1):\n",
    "        self.max_overlap = max_overlap\n",
    "        self.Xaxis = np.linspace(0, self.max_overlap, n)\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.overlaps = []\n",
    "\n",
    "    def add_overlap(self, val):\n",
    "        self.overlaps.append(val)\n",
    "\n",
    "    @property\n",
    "    def count(self):\n",
    "        return len(self.overlaps)\n",
    "\n",
    "    @property\n",
    "    def value(self):\n",
    "        # succ = [\n",
    "        #     np.sum(i >= thres\n",
    "        #            for i in self.overlaps).astype(float) / self.count\n",
    "        #     for thres in self.Xaxis\n",
    "        # ]\n",
    "        succ = [\n",
    "            np.sum(np.fromiter((i >= thres\n",
    "                   for i in self.overlaps), dtype=float)) / self.count\n",
    "            for thres in self.Xaxis\n",
    "        ]\n",
    "        \n",
    "    \n",
    "        return np.array(succ)\n",
    "\n",
    "    @property\n",
    "    def average(self):\n",
    "        if len(self.overlaps) == 0:\n",
    "            return 0\n",
    "        return np.trapz(self.value, x=self.Xaxis) * 100 / self.max_overlap\n",
    "\n",
    "\n",
    "class Sequence_t(object):\n",
    "\n",
    "    def __init__(self, name: str, dataset='/data1/yjy/rgbd_benchmark/alldata/'):\n",
    "        self._name = name\n",
    "        self._dataset = dataset\n",
    "        self._path = self._dataset + self._name\n",
    "        self._numframe = self.num_frame\n",
    "\n",
    "    @property\n",
    "    def num_frame(self):\n",
    "        try:\n",
    "            seq_list = os.listdir(os.path.join(self._path, 'color'))\n",
    "        except:\n",
    "            print('error')\n",
    "        return len(seq_list)\n",
    "    @property\n",
    "    def name(self) -> str:\n",
    "        return self._name\n",
    "\n",
    "    @property\n",
    "    def identifier(self) -> str:\n",
    "        return self._name\n",
    "\n",
    "    @property\n",
    "    def dataset(self):\n",
    "        return self._dataset\n",
    "\n",
    "    @property\n",
    "    def gt(self):\n",
    "        gtfile = os.path.join(self._path, 'groundtruth.txt')\n",
    "        with open(gtfile, 'r') as f:\n",
    "            value = np.loadtxt(f, delimiter=',')\n",
    "        \n",
    "        return value \n",
    "    @property\n",
    "    def invisible(self):\n",
    "        full_occlusion = os.path.join(self._path, 'full-occlusion.tag')\n",
    "        if not os.path.exists(full_occlusion):\n",
    "            value = np.array([0 for i in range(self._numframe)])\n",
    "        else:\n",
    "            with open(full_occlusion, 'r') as f:\n",
    "                value = np.loadtxt(f)\n",
    "        return value\n",
    "\n",
    "    @property\n",
    "    def num_inivisible(self):\n",
    "        full_occlusion = os.path.join(self._path, 'full-occlusion.tag')\n",
    "        if not os.path.exists(full_occlusion):\n",
    "            value = np.array([0 for i in range(self._numframe)])\n",
    "        else:\n",
    "            with open(full_occlusion, 'r') as f:\n",
    "                value = np.loadtxt(f)\n",
    "        if 1 in value:\n",
    "            flag = True\n",
    "            return flag, self._numframe\n",
    "        else:\n",
    "            flag = False\n",
    "            \n",
    "            return flag, self._numframe \n",
    "    # @property\n",
    "    # def attribute(self):\n",
    "    #     detattribute_list = ['aspect-change.tag', 'background-clutter.tag','depth-change.tag','fast-motion.tag', 'dark-scene.tag', 'full-occlusion.tag', 'moving-view.tag',\n",
    "    #                         'deformable.tag', 'out-of-plane.tag', 'out-of-frame.tag', 'partial-occlusion.tag', 'reflective-target.tag', 'size-change.tag', 'similar-objects.tag', 'unassigned.tag']\n",
    "    #     cdtbattribute_list = ['fast-motion.tag', 'size-change.tag', 'aspect-change.tag', 'partial-occlusion.tag', 'similar-object.tag', 'out-of-plane.tag', 'depth-change.tag', 'reflective-target.tag',\n",
    "    #                         'deformable.tag', 'dark-scene.tag', 'unassigned.tag', 'full-occlusion.tag', 'out-of-frame.tag']\n",
    "    #     allattribute_list = list(set(detattribute_list + cdtbattribute_list))\n",
    "    #     value_list = []\n",
    "    #     for attribute in allattribute_list:\n",
    "    #         attpath = os.path.join(self._path, attribute)\n",
    "    #         try:\n",
    "    #             with open(attpath, 'r') as f:\n",
    "    #                 value = np.loadtxt(f)\n",
    "    #         except:\n",
    "    #             value = None\n",
    "    #         value_list.append(value)\n",
    "    #     dict_attribute = dict.fromkeys(allattribute_list, value_list)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "class Tracking(object):\n",
    "    def __init__(self, name: str, path='/data1/yjy/rgbd_benchmark/all_benchmark/results'):\n",
    "        self._name = name\n",
    "        self._path = os.path.join(path, self._name)\n",
    "\n",
    "        self._prre = PrRe()\n",
    "        self._seqlist = self.re_list()\n",
    "        self._numseq = len(self._seqlist)\n",
    "        self._lackseq = [] \n",
    "        self._votpath = os.path.join(self._path, 'rgbd-unsupervised')\n",
    "\n",
    "    @property\n",
    "    def name(self) -> str:\n",
    "        return self._name\n",
    "    @property\n",
    "    def prre(self):\n",
    "        return self._prre\n",
    "    @property\n",
    "    def _votseqlist(self):\n",
    "        return self.vot_list()\n",
    "        \n",
    "    def lack(self, seq):\n",
    "        self._lackseq.append(seq)\n",
    "    def re_list(self):\n",
    "        seq_list = []\n",
    "        all_list = os.listdir(self._path)\n",
    "        for name in all_list:\n",
    "            if '_001.txt' in name:\n",
    "                seq = name.split('_001.txt')[0]\n",
    "                seq_list.append(seq)\n",
    "        return seq_list\n",
    "    def vot_list(self):\n",
    "\n",
    "        all_list = os.listdir(self._votpath)\n",
    "\n",
    "        return all_list\n",
    "    def vot_prebox_conf(self, sequence):\n",
    "        boxtxt = os.path.join(self._votpath, sequence,'{}_001.txt'.format(sequence))\n",
    "        try:\n",
    "            with open(boxtxt, 'r') as f:\n",
    "                pre_value = np.loadtxt(f, delimiter=',', skiprows=1)\n",
    "        except:\n",
    "            logging.debug('use \\ t in {}'.format(self._name))\n",
    "            with open(boxtxt, 'r') as f:\n",
    "                pre_value = np.loadtxt(f, delimiter='\\t', skiprows=1)\n",
    "        conftxt = os.path.join(self._votpath, sequence, '{}_001_confidence.value'.format(sequence))\n",
    "        if not os.path.exists(conftxt):\n",
    "            conftxt = os.path.join(self._votpath, sequence, '{}_001_confidence.txt'.format(sequence))\n",
    "        \n",
    "        if not os.path.exists(conftxt):\n",
    "           confidence = [1 for i in range(len(pre_value))]\n",
    "        else:\n",
    "            with open(conftxt, 'r') as f:\n",
    "                confidence = np.loadtxt(f, skiprows=1)\n",
    "        return pre_value, confidence \n",
    "\n",
    "    def prebox_conf(self, sequence):\n",
    "        boxtxt = os.path.join(self._path, '{}_001.txt'.format(sequence))\n",
    "        try:\n",
    "            with open(boxtxt, 'r') as f:\n",
    "                pre_value = np.loadtxt(f, delimiter=',', skiprows=1)\n",
    "        except:\n",
    "            logging.debug('use \\ t in {}'.format(self._name))\n",
    "            with open(boxtxt, 'r') as f:\n",
    "                pre_value = np.loadtxt(f, delimiter='\\t', skiprows=1)\n",
    "        conftxt = os.path.join(self._path, '{}_001_confidence.value'.format(sequence))\n",
    "        if not os.path.exists(conftxt):\n",
    "            conftxt = os.path.join(self._path, '{}_001_confidence.txt'.format(sequence))\n",
    "        \n",
    "        if not os.path.exists(conftxt):\n",
    "           confidence = [1 for i in range(len(pre_value))]\n",
    "        else:\n",
    "            with open(conftxt, 'r') as f:\n",
    "                confidence = np.loadtxt(f, skiprows=1)\n",
    "        return pre_value, confidence\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 precision and recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrRe(object):\n",
    "    \"\"\"Computes and stores the Success\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "        self.thresholds = np.linspace(1, 0, 100)\n",
    "    def reset(self):\n",
    "        self.overlaps = []\n",
    "        self.confidence = []\n",
    "        self.visible = []\n",
    "        self.depthQ = []\n",
    "        self.attribute_name = []\n",
    "        self.attribute_value = [[] for i in range(15)]\n",
    "        self.lt = []\n",
    "        self.start_frame = 0\n",
    "        \n",
    "    def add_overlap(self, val):\n",
    "        self.overlaps.append(val)\n",
    "\n",
    "    def add_list_iou(self, overlap:list):\n",
    "        self.overlaps = np.concatenate((self.overlaps, overlap))\n",
    "    \n",
    "    def add_confidence(self, confidence:list):\n",
    "        self.confidence = np.concatenate((self.confidence, confidence))\n",
    "    def add_visible(self, visible:list):\n",
    "        self.visible = np.concatenate((self.visible, visible))\n",
    "\n",
    "    def add_depthquality(self, depthQ:list):\n",
    "        self.depthQ = np.concatenate((self.depthQ, depthQ))\n",
    "\n",
    "    def add_attribute(self, allattribute:dict):\n",
    "        attributename = []\n",
    "        for i, key in enumerate(allattribute):\n",
    "            attributename.append(key) \n",
    "            self.attribute_value[i] = np.concatenate((self.attribute_value[i], allattribute.get(key)))\n",
    "        self.attribute_name = attributename\n",
    "        \n",
    "    def add_LT(self, firstindex, length_frame):\n",
    "        try:\n",
    "            start_frame = self.start_frame\n",
    "            first_invisible = start_frame + firstindex[0][0]\n",
    "            end_frame = start_frame + length_frame - 1\n",
    "            self.lt.append([start_frame,first_invisible, end_frame])\n",
    "            self.start_frame += length_frame\n",
    "        except:\n",
    "            start_frame = self.start_frame\n",
    "            end_frame = start_frame + length_frame - 1\n",
    "            self.lt.append([start_frame,0, end_frame])\n",
    "            self.start_frame += length_frame\n",
    "\n",
    "\n",
    "    @property\n",
    "    def count(self):\n",
    "        return len(self.overlaps)\n",
    "\n",
    "    @property\n",
    "    def value(self):\n",
    "\n",
    "        # succ = [\n",
    "        #     np.sum(np.fromiter((i >= thres\n",
    "        #            for i in self.overlaps), dtype=float)) / self.count\n",
    "        #     for thres in self.Xaxis\n",
    "        # ]\n",
    "        # return np.array(succ)\n",
    "        \n",
    "        n_visible = len([vis for vis in self.visible if vis == True])\n",
    "        precision = len(self.thresholds) * [float(0)]\n",
    "        recall = len(self.thresholds) * [float(0)]\n",
    "\n",
    "        for i, threshold in enumerate(self.thresholds):\n",
    "\n",
    "            subset = self.confidence >= threshold\n",
    "            \n",
    "            if np.sum(subset) == 0:\n",
    "                precision[i] = 1\n",
    "                recall[i] = 0\n",
    "            else:\n",
    "                try:\n",
    "                    # precision[i] = np.mean(self.overlaps[subset])\n",
    "                    precision[i] = np.mean(self.overlaps[subset])\n",
    "                    recall[i] = np.sum(self.overlaps[subset]) / n_visible\n",
    "                except:\n",
    "                    print('exception')\n",
    "                if precision[i] == np.nan or recall[i] == np.nan:\n",
    "                    print('nan')\n",
    "        return precision, recall\n",
    "    @property\n",
    "    def value_DQ(self):\n",
    "\n",
    "        '''\n",
    "            quality level: low < 0.4   medium >= 0.4 <=0.8 high > 0.8\n",
    "            all_precision: [high medium low]\n",
    "            all_reacall: [high medium low]\n",
    "        '''\n",
    "        try:\n",
    "            set1 = self.depthQ <=0.8\n",
    "            set2 = self.depthQ >= 0.4\n",
    "            lowQ_set = self.depthQ > 0.8\n",
    "            mediumQ_set = set1 == set2\n",
    "            highQ_set = self.depthQ < 0.4\n",
    "        except:\n",
    "            print('depth quality error') \n",
    "        all_set = [highQ_set,mediumQ_set, lowQ_set]\n",
    "        all_precision =[]\n",
    "        all_recall = []\n",
    "        for qualityset in range(len(all_set)):\n",
    "            confidence = self.confidence[all_set[qualityset]]\n",
    "            overlaps = self.overlaps[all_set[qualityset]]\n",
    "            visible = self.visible[all_set[qualityset]]\n",
    "            n_visible = len([vis for vis in visible if vis == True])\n",
    "            precision = len(self.thresholds) * [float(0)]\n",
    "            recall = len(self.thresholds) * [float(0)]\n",
    "\n",
    "            for i, threshold in enumerate(self.thresholds):\n",
    "\n",
    "                subset = confidence >= threshold\n",
    "                \n",
    "                if np.sum(subset) == 0:\n",
    "                    precision[i] = 1\n",
    "                    recall[i] = 0\n",
    "                else:\n",
    "                    try:\n",
    "                        # precision[i] = np.mean(self.overlaps[subset])\n",
    "                        precision[i] = np.mean(overlaps[subset])\n",
    "                        recall[i] = np.sum(overlaps[subset]) / n_visible\n",
    "                    except:\n",
    "                        print('exception')\n",
    "                    if precision[i] == np.nan or recall[i] == np.nan:\n",
    "                        print('nan')\n",
    "            all_precision.append(precision)\n",
    "            all_recall.append(recall)\n",
    "        return all_precision, all_recall\n",
    "\n",
    "    '''\n",
    "        attribute \n",
    "    '''\n",
    "    @property\n",
    "    def value_AT(self):\n",
    "        '''\n",
    "            Attribute calculate\n",
    "        '''\n",
    "        all_precision = []\n",
    "        all_recall = []\n",
    "        all_tag = self.attribute_name\n",
    "        all_value = self.attribute_value\n",
    "        for id in range(len(all_tag)):\n",
    "            index = all_value[id] ==1\n",
    "            confidence = self.confidence[index]\n",
    "            overlaps = self.overlaps[index]\n",
    "            visible = self.visible[index]\n",
    "            n_visible = len([vis for vis in visible if vis == True])\n",
    "            precision = len(self.thresholds) * [float(0)]\n",
    "            recall = len(self.thresholds) * [float(0)]\n",
    "\n",
    "            for i, threshold in enumerate(self.thresholds):\n",
    "\n",
    "                subset = confidence >= threshold\n",
    "                \n",
    "                if np.sum(subset) == 0:\n",
    "                    precision[i] = 1\n",
    "                    recall[i] = 0\n",
    "                else:\n",
    "                    try:\n",
    "                        # precision[i] = np.mean(self.overlaps[subset])\n",
    "                        precision[i] = np.mean(overlaps[subset])\n",
    "                        recall[i] = np.sum(overlaps[subset]) / n_visible\n",
    "                    except:\n",
    "                        print('exception')\n",
    "                    if precision[i] == np.nan or recall[i] == np.nan:\n",
    "                        print('nan')\n",
    "            #recall[np.isnan(recall)]=0\n",
    "            all_precision.append(precision)\n",
    "            all_recall.append(recall)\n",
    "        \n",
    "        return all_tag, all_precision, all_recall\n",
    "\n",
    "    @property\n",
    "    def value_LT(self):\n",
    "\n",
    "        '''\n",
    "            first invisible frame\n",
    "            performanc: [0: 1st invisible] [1st invisible: end]\n",
    "        '''\n",
    "        n_visible = len([vis for vis in self.visible if vis == True])\n",
    "        precision = len(self.thresholds) * [float(0)]\n",
    "        recall = len(self.thresholds) * [float(0)]\n",
    "        lt_Framelist = self.lt\n",
    "        all_result = [[],[]]\n",
    "        before_invisible = len(self.overlaps) * [float(0)]\n",
    "        after_invisible = len(self.overlaps) * [float(0)]\n",
    "        for index, framelist in enumerate(lt_Framelist):\n",
    "            start = framelist[0]\n",
    "            invisible = framelist[1]\n",
    "            end = framelist[2]\n",
    "            if invisible == 0:\n",
    "                continue\n",
    "\n",
    "            before_invisible[start:invisible] = (invisible-start) * [float(1)]\n",
    "            after_invisible[invisible:end] = (end-invisible) * [float(1)]\n",
    "\n",
    "\n",
    "\n",
    "        before_invisible = np.array(before_invisible)\n",
    "        after_invisible = np.array(after_invisible)\n",
    "        for id, frame in enumerate([before_invisible, after_invisible]):\n",
    "            x_frame = frame == 1\n",
    "            confidence = self.confidence[x_frame]\n",
    "            overlaps = self.overlaps[x_frame]\n",
    "            visible = self.visible[x_frame]\n",
    "            n_visible = len([vis for vis in visible if vis == True])\n",
    "\n",
    "            precision = len(self.thresholds) * [float(0)]\n",
    "            recall = len(self.thresholds) * [float(0)]\n",
    "\n",
    "            for i, threshold in enumerate(self.thresholds):\n",
    "\n",
    "                subset = confidence >= threshold\n",
    "                \n",
    "                if np.sum(subset) == 0:\n",
    "                    precision[i] = 1\n",
    "                    recall[i] = 0\n",
    "                else:\n",
    "                    try:\n",
    "                        # precision[i] = np.mean(self.overlaps[subset])\n",
    "                        precision[i] = np.mean(overlaps[subset])\n",
    "                        recall[i] = np.sum(overlaps[subset]) / n_visible\n",
    "                    except:\n",
    "                        print('exception')\n",
    "                    if precision[i] == np.nan or recall[i] == np.nan:\n",
    "                        print('nan')\n",
    "          \n",
    "            all_result[id] = [precision, recall]\n",
    "        return all_result\n",
    "\n",
    "    @property\n",
    "    def value_SRE(self):\n",
    "\n",
    "        # succ = [\n",
    "        #     np.sum(np.fromiter((i >= thres\n",
    "        #            for i in self.overlaps), dtype=float)) / self.count\n",
    "        #     for thres in self.Xaxis\n",
    "        # ]\n",
    "        # return np.array(succ)\n",
    "        \n",
    "        n_visible = len([vis for vis in self.visible if vis == True])\n",
    "        precision = len(self.thresholds) * [float(0)]\n",
    "        recall = len(self.thresholds) * [float(0)]\n",
    "\n",
    "        for i, threshold in enumerate(self.thresholds):\n",
    "\n",
    "            subset = self.confidence >= threshold\n",
    "            \n",
    "            if np.sum(subset) == 0:\n",
    "                precision[i] = 1\n",
    "                recall[i] = 0\n",
    "            else:\n",
    "                try:\n",
    "                    # precision[i] = np.mean(self.overlaps[subset])\n",
    "                    precision[i] = np.mean(self.overlaps[subset])\n",
    "                    recall[i] = np.sum(self.overlaps[subset]) / n_visible\n",
    "                except:\n",
    "                    print('exception')\n",
    "                if precision[i] == np.nan or recall[i] == np.nan:\n",
    "                    print('nan')\n",
    "        return precision, recall\n",
    "\n",
    "\n",
    "    @property\n",
    "    def fscore(self):\n",
    "        pr, re = self.value\n",
    "\n",
    "        # pr_score = abs(np.trapz(pr, self.thresholds))\n",
    "        pr_score = np.max(pr)\n",
    "        # re_score = abs(np.trapz(re, self.thresholds))\n",
    "        re_score = np.max(re)\n",
    "        # pr_score = np.sum(pr)/100\n",
    "        # re_score = np.sum(re)/100\n",
    "        fmeasure = [2*pr[i]*re[i]/(pr[i]+re[i]) for i in range(len(pr))]\n",
    "        fscore = max(fmeasure)\n",
    "        return pr_score, re_score, fscore\n",
    "\n",
    "    '''\n",
    "        depth quality evaluation\n",
    "        all_result:[high medium low], all_result[high] = [pr,re,f]\n",
    "    '''\n",
    "    @property\n",
    "    def fscore_DQ(self):\n",
    "        all_pr, all_re = self.value_DQ\n",
    "        all_result = []\n",
    "        for index in range(len(all_pr)):\n",
    "            pr = all_pr[index]\n",
    "            re = all_re[index]\n",
    "            pr_score = np.max(pr)\n",
    "            # re_score = abs(np.trapz(re, self.thresholds))\n",
    "            re_score = np.max(re)\n",
    "            # pr_score = np.sum(pr)/100\n",
    "            # re_score = np.sum(re)/100\n",
    "            fmeasure = [2*pr[i]*re[i]/(pr[i]+re[i]) for i in range(len(pr))]\n",
    "            fscore = max(fmeasure)\n",
    "            all_result.append(np.array([pr_score, re_score, fscore]))\n",
    "        return all_result\n",
    "    '''\n",
    "        attribute\n",
    "    '''\n",
    "    @property\n",
    "    def fscore_AT(self):\n",
    "        all_tag, all_pr, all_re = self.value_AT\n",
    "        all_result = dict()\n",
    "        all_fscore = []\n",
    "        tag_list = []\n",
    "        for index in range(len(all_pr)):\n",
    "            pr = all_pr[index]\n",
    "            re = all_re[index]\n",
    "            pr_score = np.max(pr)\n",
    "            # re_score = abs(np.trapz(re, self.thresholds))\n",
    "            re_score = np.max(re)\n",
    "            # pr_score = np.sum(pr)/100\n",
    "            # re_score = np.sum(re)/100\n",
    "            fmeasure = [2*pr[i]*re[i]/(pr[i]+re[i]) for i in range(len(pr))]\n",
    "            fscore = max(fmeasure)\n",
    "            all_fscore.append(np.array([fscore]))\n",
    "            tag_list.append(all_tag[index])\n",
    "        all_result = dict(zip(tag_list,all_fscore))\n",
    "        return all_result\n",
    "    '''\n",
    "        long term evaluation\n",
    "        first invisible\n",
    "    '''\n",
    "    @property\n",
    "    def fscore_LT(self):\n",
    "        '''\n",
    "            before result: result[0]\n",
    "            after result: result[1]\n",
    "        '''\n",
    "        all_result = self.value_LT\n",
    "        result = []\n",
    "        for id in range(len(all_result)):\n",
    "            pr = all_result[id][0]\n",
    "            re = all_result[id][1]\n",
    "            pr_score = np.max(pr)\n",
    "            # re_score = abs(np.trapz(re, self.thresholds))\n",
    "            re_score = np.max(re)\n",
    "            # pr_score = np.sum(pr)/100\n",
    "            # re_score = np.sum(re)/100\n",
    "            fmeasure = [2*pr[i]*re[i]/(pr[i]+re[i]) for i in range(len(pr))]\n",
    "            fmeasure = np.nan_to_num(np.array(fmeasure))\n",
    "            fscore = np.max(fmeasure)\n",
    "            result.append(fscore)\n",
    "        return result\n",
    "    '''\n",
    "    long term evaluation\n",
    "    first invisible\n",
    "    '''\n",
    "    @property\n",
    "    def fscore_SRE(self):\n",
    "        '''\n",
    "            before result: result[0]\n",
    "            after result: result[1]\n",
    "        '''\n",
    "        all_result = self.value_SRE\n",
    "        result = []\n",
    "        for id in range(len(all_result)):\n",
    "            pr = all_result[id][0]\n",
    "            re = all_result[id][1]\n",
    "            pr_score = np.mean(pr)\n",
    "            # re_score = abs(np.trapz(re, self.thresholds))\n",
    "            re_score = np.mean(re)\n",
    "            # pr_score = np.sum(pr)/100\n",
    "            # re_score = np.sum(re)/100\n",
    "            fmeasure = [2*pr[i]*re[i]/(pr[i]+re[i]) for i in range(len(pr))]\n",
    "            fmeasure = np.nan_to_num(np.array(fmeasure))\n",
    "            fscore = np.max(fmeasure)\n",
    "            result.append([pr_score, re_score, fscore])\n",
    "        return result  \n",
    "class Recall(object):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SRE evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSRDCF\n",
      "Trackers: CSRDCF sre: tre40  pr: 0.15838444877501642 re: 0.16559650100564283 fscore: 0.16191020211902546\n",
      "DAL\n",
      "Trackers: DAL sre: tre40  pr: 0.730509404810487 re: 0.5165897970906259 fscore: 0.5456375946241129\n",
      "DeT\n",
      "Trackers: DeT sre: tre40  pr: 0.6247433821421966 re: 0.5645487317887158 fscore: 0.5792235294508373\n",
      "iiau_rgbd\n",
      "Trackers: iiau_rgbd sre: tre40  pr: 1.0 re: 0.6661307278552203 fscore: 0.6689595050853347\n",
      "sttc_rgbd\n",
      "Trackers: sttc_rgbd sre: tre40  pr: 0.9972393100710898 re: 0.607476003603953 fscore: 0.6031746719142198\n",
      "CSRDCF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_42459/766108014.py\", line 29, in compute_SRE_curves\n",
      "    assert len(overlaps) == len(visible) == len(confidence)\n",
      "AssertionError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"_pydevd_bundle/pydevd_cython.pyx\", line 1078, in _pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\n",
      "  File \"_pydevd_bundle/pydevd_cython.pyx\", line 297, in _pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\n",
      "  File \"/home/lz/anaconda3/envs/nbconda/lib/python3.9/site-packages/debugpy/_vendored/pydevd/pydevd.py\", line 1976, in do_wait_suspend\n",
      "    keep_suspended = self._do_wait_suspend(thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\n",
      "  File \"/home/lz/anaconda3/envs/nbconda/lib/python3.9/site-packages/debugpy/_vendored/pydevd/pydevd.py\", line 2011, in _do_wait_suspend\n",
      "    time.sleep(0.01)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_42459/766108014.py\u001b[0m in \u001b[0;36mcompute_SRE_curves\u001b[0;34m(trajectory, sequence, all_prre, tre)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moverlaps\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvisible\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfidence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_42459/766108014.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     65\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msequence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrackers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_votseqlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m                     \u001b[0mcompute_SRE_curves\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrackers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrackers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prre\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtre\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tre'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m                     \u001b[0;31m#print('{}: length of iou {} '.format(trackers.name, trackers._prre.count))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_42459/766108014.py\u001b[0m in \u001b[0;36mcompute_SRE_curves\u001b[0;34m(trajectory, sequence, all_prre, tre)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moverlaps\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvisible\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfidence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"assert not equal\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mall_prre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_list_iou\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moverlaps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_42459/766108014.py\u001b[0m in \u001b[0;36mcompute_SRE_curves\u001b[0;34m(trajectory, sequence, all_prre, tre)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moverlaps\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvisible\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfidence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"assert not equal\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mall_prre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_list_iou\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moverlaps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m_pydevd_bundle/pydevd_cython.pyx\u001b[0m in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m_pydevd_bundle/pydevd_cython.pyx\u001b[0m in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m_pydevd_bundle/pydevd_cython.pyx\u001b[0m in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m_pydevd_bundle/pydevd_cython.pyx\u001b[0m in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m_pydevd_bundle/pydevd_cython.pyx\u001b[0m in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nbconda/lib/python3.9/site-packages/debugpy/_vendored/pydevd/pydevd.py\u001b[0m in \u001b[0;36mdo_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[1;32m   1974\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1975\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_threads_suspended_single_notification\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify_thread_suspended\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthread_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_reason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1976\u001b[0;31m                 \u001b[0mkeep_suspended\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_wait_suspend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuspend_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_this_thread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframes_tracker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1977\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1978\u001b[0m         \u001b[0mframes_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nbconda/lib/python3.9/site-packages/debugpy/_vendored/pydevd/pydevd.py\u001b[0m in \u001b[0;36m_do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2010\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_internal_commands\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2011\u001b[0;31m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2013\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcancel_async_evaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_current_thread_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthread\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def compute_SRE_curves(trajectory: Tracking, sequence: Sequence_t, all_prre: PrRe, tre=1):\n",
    "    \n",
    "    #overlaps = np.array(calculate_overlaps(trajectory, sequence.groundtruth(), (sequence.size) if bounded else None))\n",
    "    prebbox, confidence = trajectory.vot_prebox_conf(sequence.name)\n",
    "    gt = sequence.gt \n",
    "\n",
    "    # firstframe in each sequence\n",
    "    try:\n",
    "        overlaps = np.concatenate(([1], np.array([estimateIOU(prebbox[i], gt[i+tre] ) for i in range(len(prebbox))])))\n",
    "        overlaps[np.isnan(overlaps)]=0\n",
    "        confidence = np.concatenate(([1], np.array(confidence)))\n",
    "    except:\n",
    "        print('ok')\n",
    "\n",
    "\n",
    "    #n_visible = len([region for region in sequence.groundtruth() if region.type is not RegionType.SPECIAL])\n",
    "    # sequence.invisible (full-occlusion tag) if invisible= 1 full-occlusion invisible\n",
    "    visible = np.array(sequence.invisible) < 1\n",
    "    visible = visible + 0\n",
    "    '''\n",
    "        temporal evaluation\n",
    "    '''\n",
    "\n",
    "    visible = visible[tre-1:]\n",
    "    '''\n",
    "        temporal evaluation\n",
    "    '''\n",
    "    try:\n",
    "        assert len(overlaps) == len(visible) == len(confidence)\n",
    "    except:\n",
    "        print(\"assert not equal\")\n",
    "        print(\"Error Tracker: {} sequence {} sequence frame {} result frame {}\".format(trajectory.name, sequence.name, len(sequence.gt), len(prebbox)))\n",
    "        return False    \n",
    "\n",
    "    all_prre.add_list_iou(overlaps)\n",
    "    all_prre.add_visible(visible)\n",
    "    all_prre.add_confidence(confidence) \n",
    "\n",
    "\n",
    "seq_list = os.listdir('/data1/yjy/rgbd_benchmark/alldata')\n",
    "seq_list.remove('list.txt')\n",
    "\n",
    "SRE_workspace = '/data1/yjy/rgbd_benchmark/all_benchmark/SRE_workspace'\n",
    "sre_list = os.listdir(SRE_workspace)\n",
    "#sre_tracker = ['DAL', 'CSRDCF', 'TSDM', 'DeT', 'iiau_rgbd', 'sttc_rgbd']\n",
    "sre_tracker = [ 'CSRDCF','DAL', 'DeT', 'iiau_rgbd', 'sttc_rgbd']\n",
    "sre_average_fscore = [[] for i in range(len(sre_tracker))]\n",
    "sre_average_pr = [[] for i in range(len(sre_tracker))]\n",
    "sre_average_re = [[] for i in range(len(sre_tracker))]\n",
    "tre_average_fscore = [[] for i in range(len(sre_tracker))]\n",
    "tre_average_re = [[] for i in range(len(sre_tracker))]\n",
    "tre_average_pr = [[] for i in range(len(sre_tracker))]\n",
    "for sre in sre_list:\n",
    "    if sre=='tre10' or sre =='tre20' or sre=='tre40' or sre=='tre50':\n",
    "       # all_trackers = [Tracking(tracker) for tracker in os.listdir('/data1/yjy/rgbd_benchmark/all_benchmark/results/')]\n",
    "        # all_trackers = [Tracking(tracker, path=os.path.join(SRE_workspace, sre, 'results')) for i,tracker in enumerate(['DAL'])]\n",
    "        all_trackers = [Tracking(tracker, path=os.path.join(SRE_workspace, sre, 'results')) for i,tracker in enumerate(sre_tracker)]\n",
    "        # all_trackers = [Tracking(tracker) for tracker in ['CADMS']]\n",
    "        all_sequence = [Sequence_t(seq) for seq in seq_list]\n",
    "\n",
    "        for id, trackers in enumerate(all_trackers):\n",
    "            print(trackers.name)\n",
    "            \n",
    "            for sequence in all_sequence:\n",
    "          \n",
    "                if not os.path.exists(os.path.join(trackers._votpath, sequence.name, '{}_001.txt'.format(sequence.name))):\n",
    "                    continue\n",
    "                if sequence.name in trackers._votseqlist:\n",
    "                    compute_SRE_curves(trackers, sequence, trackers._prre, tre=int(sre.split('tre')[1]))\n",
    "                    #print('{}: length of iou {} '.format(trackers.name, trackers._prre.count))\n",
    "                else:\n",
    "                    trackers.lack(sequence.name)\n",
    "                    continue\n",
    "                \n",
    "            pr,re,fscore = trackers._prre.fscore\n",
    "            if trackers.name == sre_tracker[id]:\n",
    "                tre_average_fscore[id].append(fscore)\n",
    "                tre_average_pr[id].append(pr)\n",
    "                tre_average_re[id].append(re)\n",
    "            print('Trackers: {} sre: {}  pr: {} re: {} fscore: {}'.format(trackers.name, sre, pr, re, fscore))\n",
    "    else:\n",
    "        continue\n",
    "# all_trackers = [Tracking(tracker) for tracker in os.listdir('/data1/yjy/rgbd_benchmark/all_benchmark/results/')]\n",
    "    # all_trackers = [Tracking(tracker, path=os.path.join(SRE_workspace, sre, 'results')) for i,tracker in enumerate(sre_tracker)]\n",
    "    # # all_trackers = [Tracking(tracker) for tracker in ['CADMS']]\n",
    "    # all_sequence = [Sequence_t(seq) for seq in seq_list]\n",
    "\n",
    "    # for id, trackers in enumerate(all_trackers):\n",
    "    #     print(trackers.name)\n",
    "    #     for sequence in all_sequence:\n",
    "    #         if not os.path.exists(os.path.join(trackers._votpath, sequence.name, '{}_001.txt'.format(sequence.name))):\n",
    "    #             continue\n",
    "    #         if sequence.name in trackers._votseqlist:\n",
    "    #             compute_SRE_curves(trackers, sequence, trackers._prre)\n",
    "    #             #print('{}: length of iou {} '.format(trackers.name, trackers._prre.count))\n",
    "    #         else:\n",
    "    #             trackers.lack(sequence.name)\n",
    "    #             continue\n",
    "            \n",
    "    #     pr,re,fscore = trackers._prre.fscore\n",
    "    #     if trackers.name == sre_tracker[id]:\n",
    "    #         sre_average_fscore[id].append(fscore)\n",
    "    #         sre_average_pr[id].append(pr)\n",
    "    #         sre_average_re[id].append(re)\n",
    "    #     print('Trackers: {} sre: {}  pr: {} re: {} fscore: {}'.format(trackers.name, sre, pr, re, fscore))\n",
    "        # logging.info('Trackers: {}  Seq_num: {} frame_num: {}  pr: {}  re: {}  fscore: {}'.format(trackers.name, trackers._numseq, trackers._prre.count, pr, re, fscore))\n",
    "\n",
    "for i, sre in enumerate(sre_average_fscore):\n",
    "    trackerID = sre_tracker[i]\n",
    "    srefscore = np.mean(np.array(sre))\n",
    "    srepr = np.mean(np.array(sre_average_pr[i]))\n",
    "    srere = np.mean(np.array(sre_average_re[i]))\n",
    "    print('Trackers: {} sre pr:{} re: {} fscore: {}'.format(trackerID, srepr, srere, srefscore))\n",
    "\n",
    "    logging.info('Trackers: {} sre pr:{} re: {} fscore: {}'.format(trackerID, srepr, srere, srefscore))\n",
    "for i, tre in enumerate(tre_average_fscore):\n",
    "    trackerID = sre_tracker[i]\n",
    "    trefscore = np.mean(np.array(tre))\n",
    "    print('Trackers: {} tre fscore: {}'.format(trackerID, trefscore))\n",
    "    logging.info('Trackers: {} tre fscore: {}'.format(trackerID, trefscore))\n",
    "\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Long-term evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_LT_curves(trajectory: Tracking, sequence: Sequence_t, all_prre: PrRe):\n",
    "    \n",
    "    #overlaps = np.array(calculate_overlaps(trajectory, sequence.groundtruth(), (sequence.size) if bounded else None))\n",
    "    prebbox, confidence = trajectory.prebox_conf(sequence.name)\n",
    "    gt = sequence.gt \n",
    "\n",
    "    # firstframe in each sequence\n",
    "    overlaps = np.concatenate(([1], np.array([estimateIOU(prebbox[i], gt[i+1] ) for i in range(len(prebbox))])))\n",
    "    overlaps[np.isnan(overlaps)]=0\n",
    "    confidence = np.concatenate(([1], np.array(confidence)))\n",
    "\n",
    "\n",
    "    #n_visible = len([region for region in sequence.groundtruth() if region.type is not RegionType.SPECIAL])\n",
    "    # sequence.invisible (full-occlusion tag) if invisible= 1 full-occlusion invisible\n",
    "    visible = np.array(sequence.invisible) < 1\n",
    "    visible = visible + 0\n",
    "    try:\n",
    "        assert len(overlaps) == len(visible) == len(confidence)\n",
    "    except:\n",
    "        print(\"assert not equal\")\n",
    "    first_invisible = np.argwhere(visible == 0)\n",
    "    all_prre.add_LT(first_invisible, len(overlaps))    \n",
    "    all_prre.add_list_iou(overlaps)\n",
    "    all_prre.add_visible(visible)\n",
    "    all_prre.add_confidence(confidence) \n",
    "\n",
    "\n",
    "seq_list = os.listdir('/data1/yjy/rgbd_benchmark/alldata')\n",
    "seq_list.remove('list.txt')\n",
    "# all_trackers = [Tracking(tracker) for tracker in os.listdir('/data1/yjy/rgbd_benchmark/all_benchmark/results/')]\n",
    "all_trackers = [Tracking(tracker) for tracker in ['DAL']]\n",
    "# all_trackers = [Tracking(tracker) for tracker in ['CADMS']]\n",
    "all_sequence = [Sequence_t(seq) for seq in seq_list]\n",
    "\n",
    "for trackers in all_trackers:\n",
    "    print(trackers.name)\n",
    "    for sequence in all_sequence:\n",
    "        \n",
    "        if sequence.name in trackers._seqlist:\n",
    "            compute_LT_curves(trackers, sequence, trackers._prre)\n",
    "            #print('{}: length of iou {} '.format(trackers.name, trackers._prre.count))\n",
    "        else:\n",
    "            trackers.lack(sequence.name)\n",
    "            continue\n",
    "    \n",
    "    result = trackers._prre.fscore_LT\n",
    "    before = result[0]\n",
    "    after = result[1]\n",
    "    print('Trackers: {}  {}  fscore: {}'.format(trackers.name, 'before invisible', before))\n",
    "    print('Trackers: {}  {}  fscore: {}'.format(trackers.name, 'after invisible', after))\n",
    "    logging.info('Trackers: {}  {}  fscore: {}'.format(trackers.name, 'before invisible', before))\n",
    "    logging.info('Trackers: {}  {}  fscore: {}'.format(trackers.name, 'after invisible', after))\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attribute evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ATT_curves(trajectory: Tracking, sequence: Sequence_t, all_prre: PrRe):\n",
    "\n",
    "    #overlaps = np.array(calculate_overlaps(trajectory, sequence.groundtruth(), (sequence.size) if bounded else None))\n",
    "    prebbox, confidence = trajectory.prebox_conf(sequence.name)\n",
    "    gt = sequence.gt \n",
    "\n",
    "    # firstframe in each sequence\n",
    "    overlaps = np.concatenate(([1], np.array([estimateIOU(prebbox[i], gt[i+1] ) for i in range(len(prebbox))])))\n",
    "    overlaps[np.isnan(overlaps)]=0\n",
    "    confidence = np.concatenate(([1], np.array(confidence)))\n",
    "\n",
    "\n",
    "    #n_visible = len([region for region in sequence.groundtruth() if region.type is not RegionType.SPECIAL])\n",
    "    # sequence.invisible (full-occlusion tag) if invisible= 1 full-occlusion invisible\n",
    "    visible = np.array(sequence.invisible) < 1\n",
    "    visible = visible + 0\n",
    "    try:\n",
    "        assert len(overlaps) == len(visible) == len(confidence)\n",
    "    except:\n",
    "        print(\"assert not equal\")\n",
    "    all_attribute = attribute_index(sequence._path, len(overlaps))\n",
    "    all_prre.add_attribute(all_attribute)    \n",
    "    all_prre.add_list_iou(overlaps)\n",
    "    all_prre.add_visible(visible)\n",
    "    all_prre.add_confidence(confidence) \n",
    "\n",
    "def attribute_index(sequencepath, frame_num):\n",
    "    \n",
    "    '''\n",
    "        return: dict {tag} [value]\n",
    "    '''\n",
    "    detattribute_list = ['aspect-change.tag', 'background-clutter.tag','depth-change.tag','fast-motion.tag', 'dark-scene.tag', 'moving-view.tag',\n",
    "                    'deformable.tag', 'out-of-plane.tag', 'out-of-frame.tag', 'partial-occlusion.tag', 'reflective-target.tag', 'size-change.tag', 'similar-objects.tag', 'unassigned.tag']\n",
    "    cdtbattribute_list = ['fast-motion.tag', 'size-change.tag', 'aspect-change.tag', 'partial-occlusion.tag', 'similar-object.tag', 'out-of-plane.tag', 'depth-change.tag', 'reflective-target.tag',\n",
    "                    'deformable.tag', 'dark-scene.tag', 'unassigned.tag', 'out-of-frame.tag']\n",
    "    allattribute_list = list(set(detattribute_list + cdtbattribute_list))\n",
    "    value_list = []\n",
    "    att_name = []\n",
    "    for i, attribute in enumerate(allattribute_list):\n",
    "        # if attribute == 'background-clutter.tag':\n",
    "        #     print('ok')\n",
    "        attpath = os.path.join(sequencepath, attribute)\n",
    "        try:\n",
    "            with open(attpath, 'r') as f:\n",
    "                value = np.loadtxt(f)\n",
    "            assert len(value) == frame_num\n",
    "        except:\n",
    "            value = np.zeros(frame_num)\n",
    "        value_list.append(value)\n",
    "        att_name.append(allattribute_list[i])\n",
    "    dict_attribute = dict(zip(att_name, value_list))\n",
    "    return dict_attribute\n",
    "\n",
    "seq_list = os.listdir('/data1/yjy/rgbd_benchmark/alldata')\n",
    "seq_list.remove('list.txt')\n",
    "# all_trackers = [Tracking(tracker) for tracker in os.listdir('/data1/yjy/rgbd_benchmark/all_benchmark/results/')]\n",
    "all_trackers = [Tracking(tracker) for tracker in ['DeT']]\n",
    "all_sequence = [Sequence_t(seq) for seq in seq_list]\n",
    "\n",
    "output_tracker = []\n",
    "output_fscore = [[] for i in range(15)]\n",
    "tag_list = []\n",
    "for trackers in all_trackers:\n",
    "    print(trackers.name)\n",
    "    for sequence in all_sequence:\n",
    "        \n",
    "        if sequence.name in trackers._seqlist:\n",
    "            compute_ATT_curves(trackers, sequence, trackers._prre)\n",
    "            #print('{}: length of iou {} '.format(trackers.name, trackers._prre.count))\n",
    "        else:\n",
    "            trackers.lack(sequence.name)\n",
    "            continue\n",
    "        \n",
    "    result = trackers._prre.fscore_AT\n",
    "    print('Trackers: {}'.format(trackers.name))\n",
    "    for index, tag in enumerate(result):\n",
    "        print('{}   fscore: {}'.format(tag, result.get(tag)))\n",
    "        output_fscore[index].append(result.get(tag))\n",
    "        logging.info('Trackers: {} attribute:{}   fscore: {}'.format(trackers.name, tag, result.get(tag)))\n",
    "        tag_list.append(tag)\n",
    "    output_tracker.append(trackers.name)\n",
    "print('Trackers: ', output_tracker)\n",
    "outputfile = open('/home/lz/TMM2022/experiment_metric/result/attribute.txt', 'w')\n",
    "outputfile.writelines('Trackers: {}'.format(output_tracker))\n",
    "outputfile.writelines('\\n')\n",
    "for i in range(len(output_fscore)):\n",
    "    str_output = '{} fscore: {}'.format(tag_list[i],output_fscore[i])\n",
    "    outputfile.writelines(str_output)\n",
    "    outputfile.writelines('\\n')\n",
    "outputfile.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall performance\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DSKCF\n",
      "Trackers: DSKCF  Seq_num: 164 frame_num: 180373  pr: 0.007326815629597605  re: 0.007666815851331459  fscore: 0.007492960765406419\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_42459/3142085485.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mpr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrackers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfscore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Trackers: {}  Seq_num: {} frame_num: {}  pr: {}  re: {}  fscore: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrackers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrackers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numseq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrackers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Trackers: {}  Seq_num: {} frame_num: {}  pr: {}  re: {}  fscore: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrackers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrackers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numseq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrackers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_42459/3142085485.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mpr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrackers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfscore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Trackers: {}  Seq_num: {} frame_num: {}  pr: {}  re: {}  fscore: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrackers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrackers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numseq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrackers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Trackers: {}  Seq_num: {} frame_num: {}  pr: {}  re: {}  fscore: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrackers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrackers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numseq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrackers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m_pydevd_bundle/pydevd_cython.pyx\u001b[0m in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m_pydevd_bundle/pydevd_cython.pyx\u001b[0m in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m_pydevd_bundle/pydevd_cython.pyx\u001b[0m in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m_pydevd_bundle/pydevd_cython.pyx\u001b[0m in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m_pydevd_bundle/pydevd_cython.pyx\u001b[0m in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nbconda/lib/python3.9/site-packages/debugpy/_vendored/pydevd/pydevd.py\u001b[0m in \u001b[0;36mdo_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[1;32m   1974\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1975\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_threads_suspended_single_notification\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify_thread_suspended\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthread_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_reason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1976\u001b[0;31m                 \u001b[0mkeep_suspended\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_wait_suspend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuspend_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_this_thread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframes_tracker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1977\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1978\u001b[0m         \u001b[0mframes_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nbconda/lib/python3.9/site-packages/debugpy/_vendored/pydevd/pydevd.py\u001b[0m in \u001b[0;36m_do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2010\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_internal_commands\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2011\u001b[0;31m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2013\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcancel_async_evaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_current_thread_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthread\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def compute_tpr_curves(trajectory: Tracking, sequence: Sequence_t, all_prre: PrRe):\n",
    "    \n",
    "    #overlaps = np.array(calculate_overlaps(trajectory, sequence.groundtruth(), (sequence.size) if bounded else None))\n",
    "    prebbox, confidence = trajectory.prebox_conf(sequence.name)\n",
    "    gt = sequence.gt \n",
    "\n",
    "    # firstframe in each sequence\n",
    "    overlaps = np.concatenate(([1], np.array([estimateIOU(prebbox[i], gt[i+1] ) for i in range(len(prebbox))])))\n",
    "    overlaps[np.isnan(overlaps)]=0\n",
    "    confidence = np.concatenate(([1], np.array(confidence)))\n",
    "\n",
    "\n",
    "    #n_visible = len([region for region in sequence.groundtruth() if region.type is not RegionType.SPECIAL])\n",
    "    # sequence.invisible (full-occlusion tag) if invisible= 1 full-occlusion invisible\n",
    "    visible = np.array(sequence.invisible) < 1\n",
    "    visible = visible + 0\n",
    "    try:\n",
    "        assert len(overlaps) == len(visible) == len(confidence)\n",
    "    except:\n",
    "        print(\"assert not equal\")    \n",
    "    all_prre.add_list_iou(overlaps)\n",
    "    all_prre.add_visible(visible)\n",
    "    all_prre.add_confidence(confidence) \n",
    "\n",
    "\n",
    "seq_list = os.listdir('/data1/yjy/rgbd_benchmark/alldata')\n",
    "seq_list.remove('list.txt')\n",
    "# all_trackers = [Tracking(tracker) for tracker in os.listdir('/data1/yjy/rgbd_benchmark/all_benchmark/results/')]\n",
    "# all_trackers = [Tracking(tracker) for tracker in ['DAL']]\n",
    "all_trackers = [Tracking(tracker) for tracker in ['DSKCF']]\n",
    "all_sequence = [Sequence_t(seq) for seq in seq_list]\n",
    "\n",
    "for trackers in all_trackers:\n",
    "    print(trackers.name)\n",
    "    for sequence in all_sequence:\n",
    "        \n",
    "        if sequence.name in trackers._seqlist:\n",
    "            compute_tpr_curves(trackers, sequence, trackers._prre)\n",
    "            #print('{}: length of iou {} '.format(trackers.name, trackers._prre.count))\n",
    "        else:\n",
    "            trackers.lack(sequence.name)\n",
    "            continue\n",
    "    \n",
    "    pr,re,fscore = trackers._prre.fscore\n",
    "    print('Trackers: {}  Seq_num: {} frame_num: {}  pr: {}  re: {}  fscore: {}'.format(trackers.name, trackers._numseq, trackers._prre.count, pr, re, fscore))\n",
    "    logging.info('Trackers: {}  Seq_num: {} frame_num: {}  pr: {}  re: {}  fscore: {}'.format(trackers.name, trackers._numseq, trackers._prre.count, pr, re, fscore))\n",
    "\n",
    "\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: container_room_noocc_1, frame: 1644\n"
     ]
    }
   ],
   "source": [
    "#print('name: {}, frame: {}'.format(all_sequence[1].name, all_sequence[1]._numframe))\n",
    "# prebbox, confidence = all_trackers[2].prebox_conf(all_sequence[2].name)\n",
    "# for trackers in all_trackers:\n",
    "\n",
    "#     print('name: {} \\t \\t number of seq {} '.format(trackers.name, trackers._numseq))     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Depth quality evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import scipy\n",
    "# import scipy.io\n",
    "# mat_det = scipy.io.loadmat('/data1/yjy/rgbd_benchmark/all_benchmark/depthquality/det.mat')\n",
    "# mat_cdtb = scipy.io.loadmat('/data1/yjy/rgbd_benchmark/all_benchmark/depthquality/cdtb_25.mat')\n",
    "# mat_stc = scipy.io.loadmat('/data1/yjy/rgbd_benchmark/all_benchmark/depthquality/stc_all.mat') \n",
    "# det = mat_det['S'][0]\n",
    "# cdtb = mat_cdtb['A'][0]\n",
    "# stc = mat_stc['S'][0]\n",
    "# sequence_listQ = []\n",
    "# depthQ = []\n",
    "# for matfile in [det]:\n",
    "#     for result in matfile:\n",
    "#         sequence_name = str(result[0]).split(\"'\")[1]\n",
    "#         sequence_depthQ =  result[1][0]\n",
    "#         sequence_listQ.append(sequence_name)\n",
    "#         depthQ.append(sequence_depthQ)\n",
    "\n",
    "# for i in range(len(cdtb)-1):\n",
    "#     sequence_name = str(cdtb[i][0]).split(\"'\")[1]\n",
    "#     sequence_depthQ = cdtb[i][1][0]\n",
    "#     sequence_listQ.append(sequence_name)\n",
    "#     depthQ.append(sequence_depthQ)\n",
    "\n",
    "# print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_DQ(trajectory: Tracking, sequence: Sequence_t, all_prre: PrRe, depthQ):\n",
    "\n",
    "    #overlaps = np.array(calculate_overlaps(trajectory, sequence.groundtruth(), (sequence.size) if bounded else None))\n",
    "    prebbox, confidence = trajectory.prebox_conf(sequence.name)\n",
    "    gt = sequence.gt \n",
    "\n",
    "    # firstframe in each sequence\n",
    "    overlaps = np.concatenate(([1], np.array([estimateIOU(prebbox[i], gt[i+1] ) for i in range(len(prebbox))])))\n",
    "    overlaps[np.isnan(overlaps)]=0\n",
    "    confidence = np.concatenate(([1], np.array(confidence)))\n",
    "\n",
    "\n",
    "    #n_visible = len([region for region in sequence.groundtruth() if region.type is not RegionType.SPECIAL])\n",
    "    # sequence.invisible (full-occlusion tag) if invisible= 1 full-occlusion invisible\n",
    "    visible = np.array(sequence.invisible) < 1\n",
    "    visible = visible + 0\n",
    "    try:\n",
    "        assert len(overlaps) == len(visible) == len(confidence) == len(depthQ)\n",
    "    except:\n",
    "        print(\"assert not equal\")    \n",
    "    all_prre.add_list_iou(overlaps)\n",
    "    all_prre.add_visible(visible)\n",
    "    all_prre.add_confidence(confidence)\n",
    "    all_prre.add_depthquality(depthQ) \n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "    depth quality \n",
    "'''\n",
    "mat_det = scipy.io.loadmat('/data1/yjy/rgbd_benchmark/all_benchmark/depthquality/det.mat')\n",
    "mat_cdtb = scipy.io.loadmat('/data1/yjy/rgbd_benchmark/all_benchmark/depthquality/cdtb_25.mat')\n",
    "mat_stc = scipy.io.loadmat('/data1/yjy/rgbd_benchmark/all_benchmark/depthquality/stc_all.mat') \n",
    "det = mat_det['S'][0]\n",
    "cdtb = mat_cdtb['A'][0]\n",
    "stc = mat_stc['S'][0]\n",
    "sequence_listQ = []\n",
    "depthQ = []\n",
    "for matfile in [det,stc]:\n",
    "    for result in matfile:\n",
    "        sequence_name = str(result[0]).split(\"'\")[1]\n",
    "        sequence_depthQ =  result[1][0]\n",
    "        sequence_listQ.append(sequence_name)\n",
    "        depthQ.append(sequence_depthQ)\n",
    "\n",
    "for i in range(len(cdtb)-1):\n",
    "    sequence_name = str(cdtb[i][0]).split(\"'\")[1]\n",
    "    sequence_depthQ = cdtb[i][1][0]\n",
    "    sequence_listQ.append(sequence_name)\n",
    "    depthQ.append(sequence_depthQ)\n",
    "'''\n",
    "    depth quality\n",
    "'''\n",
    "seq_list = os.listdir('/data1/yjy/rgbd_benchmark/alldata')\n",
    "seq_list.remove('list.txt')\n",
    "all_trackers = [Tracking(tracker) for tracker in os.listdir('/data1/yjy/rgbd_benchmark/all_benchmark/results/')]\n",
    "# all_trackers = [Tracking(tracker) for tracker in ['DAL']]\n",
    "all_sequence = [Sequence_t(sequence_listQ[i]) for i in range(len(sequence_listQ))]\n",
    "\n",
    "for trackers in all_trackers:\n",
    "    print(trackers.name)\n",
    "    for i in range(len(all_sequence)):\n",
    "        \n",
    "        if all_sequence[i].name in trackers._seqlist:\n",
    "            compute_DQ(trackers, all_sequence[i], trackers._prre, depthQ[i])\n",
    "            #print('{}: length of iou {} '.format(trackers.name, trackers._prre.count))\n",
    "        else:\n",
    "            trackers.lack(all_sequence[i].name)\n",
    "            continue\n",
    "    \n",
    "    result = trackers.prre.fscore_DQ\n",
    "    list_quality = ['high quality', 'medium quality', 'low quality']\n",
    "    for qualityID in range(len(result)):\n",
    "\n",
    "        pr,re,fscore = result[qualityID]\n",
    "        print('Trackers: {} quality level: {}   pr: {}  re: {}  fscore: {}'.format(trackers.name,list_quality[qualityID],pr, re, fscore))\n",
    "        logging.info('Trackers: {}  quality level: {}  pr: {}  re: {}  fscore: {}'.format(trackers.name, list_quality[qualityID], pr, re, fscore))\n",
    "\n",
    "\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.4 0.8\n",
    "all_value = 0\n",
    "num = 0\n",
    "depth_quality = []\n",
    "for depth in depthQ:\n",
    "    for value in depth:\n",
    "        all_value += value\n",
    "        num+=1\n",
    "        depth_quality.append(value)\n",
    "Z = np.array(depth_quality)\n",
    "mean = all_value / num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## calculate auc of iou "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_35807/2209188759.py:76: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  np.sum(i >= thres\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATCAIS19 iou auc: 66.43529551954242\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# tracker_name = ['DDiMP', 'ATCAIS', 'DRefine', 'SLMD', 'Siam_LTD', 'TSDM', 'iiau_rgbd']\n",
    "tracker_name = ['ATCAIS19']\n",
    "gt_dir = '/data1/yjy/rgbd_benchmark/stc_benchmark/RGBDdataset/'\n",
    "su = Success()\n",
    "for tracker in tracker_name:\n",
    "    su.reset()\n",
    "    tracking_result_dir = '/home/yangjinyu/rgbd_tracker/benchmark_workspace/stc_workspace/results/{}/rgbd-unsupervised'.format(tracker)\n",
    "    seqlist = os.listdir(tracking_result_dir)\n",
    "    for seq in seqlist:\n",
    "        gt_seq = os.path.join(gt_dir, seq, 'groundtruth.txt' )\n",
    "        pre_seq = os.path.join(tracking_result_dir, '{}/{}_001.txt'.format(seq, seq))\n",
    "        with open(gt_seq, 'r') as f:\n",
    "            gt_value = np.loadtxt(f, delimiter=',', skiprows=1)\n",
    "        with open(pre_seq, 'r') as f:\n",
    "            pre_value = np.loadtxt(f, delimiter=',', skiprows=1)\n",
    "        if not len(gt_value) == len(pre_value):\n",
    "            raise TypeError\n",
    "        for i in range(len(gt_value)):\n",
    "            iou = estimateIOU(gt_value[i], pre_value[i])\n",
    "            su.add_overlap(iou)\n",
    "    print('{} iou auc: {}'.format(tracker, su.average))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### stc tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stc iou auc: 39.79200786112021\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# tracker_name = ['DDiMP', 'ATCAIS', 'DRefine', 'SLMD', 'Siam_LTD', 'TSDM', 'iiau_rgbd']\n",
    "tracker_name = ['stc']\n",
    "gt_dir = '/data1/yjy/rgbd_benchmark/stc_benchmark/RGBDdataset/'\n",
    "su = Success()\n",
    "for tracker in tracker_name:\n",
    "    su.reset()\n",
    "    tracking_result_dir = '/home/yangjinyu/rgbd_tracker/benchmark_workspace/stc_workspace/results/{}/rgbd-unsupervised'.format(tracker)\n",
    "    seqlist = os.listdir(tracking_result_dir)\n",
    "    for seqtxt in seqlist:\n",
    "        gt_seq = os.path.join(gt_dir, seqtxt.split('.')[0], 'groundtruth.txt' )\n",
    "        pre_seq = os.path.join(tracking_result_dir, seqtxt)\n",
    "        with open(gt_seq, 'r') as f:\n",
    "            gt_value = np.loadtxt(f, delimiter=',', skiprows=1)\n",
    "        with open(pre_seq, 'r') as f:\n",
    "            pre_value = np.loadtxt(f, delimiter=',', skiprows=1)\n",
    "        if not len(gt_value) == len(pre_value):\n",
    "            raise TypeError\n",
    "        for i in range(len(gt_value)):\n",
    "            iou = estimateIOU(gt_value[i], pre_value[i])\n",
    "            su.add_overlap(iou)\n",
    "    print('{} iou auc: {}'.format(tracker, su.average))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### copy result to all_benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66 98558\n"
     ]
    }
   ],
   "source": [
    "seq_list = os.listdir('/data1/yjy/rgbd_benchmark/alldata')\n",
    "seq_list.remove('list.txt')\n",
    "# all_trackers = [Tracking(tracker) for tracker in ['DAL']]\n",
    "all_sequence = [Sequence_t(seq) for seq in seq_list]\n",
    "count_frame = 0\n",
    "count_seq = 0\n",
    "for seq in all_sequence:\n",
    "    flag, framenum = seq.num_inivisible\n",
    "    if flag:\n",
    "        count_seq += 1\n",
    "        count_frame += framenum\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "print(count_seq, count_frame)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5d961e761471cb2a6ecd0e717f761ad980996fff136378d2cdef2349e503c6df"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('nb_conda': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
