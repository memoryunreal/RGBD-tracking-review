{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metric (Lasot and vot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Success and Precsion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from typing import List, Iterable, Tuple, Any\n",
    "import itertools\n",
    "import sys\n",
    "sys.path.append('/home/lz/anaconda3/envs/nbconda/lib/python3.9/site-packages/vot/')\n",
    "from attributee import Float, Integer, Boolean, Include\n",
    "import os\n",
    "from vot.tracker import Tracker\n",
    "from vot.dataset import Sequence\n",
    "from vot.region import Region, RegionType, calculate_overlaps\n",
    "from vot.experiment import Experiment\n",
    "from vot.experiment.multirun import UnsupervisedExperiment\n",
    "from vot.analysis import SequenceAggregator, Analysis, SeparableAnalysis, \\\n",
    "    MissingResultsException, Measure, Sorting, Curve, Plot, SequenceAggregator, \\\n",
    "    Axes, analysis_registry\n",
    "from vot.utilities.data import Grid\n",
    "import numpy as np\n",
    "from shapely.geometry import Polygon\n",
    "\n",
    "import logging\n",
    "log_path = os.path.join(os.getcwd(), 'metric.log')\n",
    "logging.basicConfig(filename=log_path, level=logging.DEBUG, filemode='w', format='%(levelname)s:%(asctime)s:%(message)s', datefmt='%Y-%d-%m %H:%M:%S')\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def estimateIOU(box_a, box_b):\n",
    "    if str(box_b[0]) == 'nan':\n",
    "        return 0\n",
    "    areaA = box_a[2] * box_a[3]\n",
    "    areaB = box_b[2] * box_b[3]\n",
    "\n",
    "    area_sum = areaA + areaB\n",
    "    max_a_x = box_a[0] + box_a[2]\n",
    "    max_a_y = box_a[1] + box_a[3]\n",
    "\n",
    "    max_b_x = box_b[0] + box_b[2]\n",
    "    max_b_y = box_b[1] + box_b[3]\n",
    "\n",
    "    inter_x_max = min(max_a_x, max_b_x)\n",
    "    inter_y_max = min(max_a_y, max_b_y)\n",
    "    inter_x_min = max(box_a[0], box_b[0])\n",
    "    inter_y_min = max(box_a[1], box_b[1])\n",
    "    inter_w = inter_x_max - inter_x_min\n",
    "    inter_h = inter_y_max - inter_y_min\n",
    "    if inter_w<=0 or inter_h<=0:\n",
    "        inter_area = 0 \n",
    "    else:\n",
    "        inter_area = inter_w * inter_h\n",
    "\n",
    "    overlap = inter_area  / (area_sum - inter_area)\n",
    "    return overlap\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Success(object):\n",
    "    \"\"\"Computes and stores the Success\"\"\"\n",
    "\n",
    "    def __init__(self, n=21, max_overlap=1):\n",
    "        self.max_overlap = max_overlap\n",
    "        self.Xaxis = np.linspace(0, self.max_overlap, n)\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.overlaps = []\n",
    "\n",
    "    def add_overlap(self, val):\n",
    "        self.overlaps.append(val)\n",
    "\n",
    "    @property\n",
    "    def count(self):\n",
    "        return len(self.overlaps)\n",
    "\n",
    "    @property\n",
    "    def value(self):\n",
    "        # succ = [\n",
    "        #     np.sum(i >= thres\n",
    "        #            for i in self.overlaps).astype(float) / self.count\n",
    "        #     for thres in self.Xaxis\n",
    "        # ]\n",
    "        succ = [\n",
    "            np.sum(np.fromiter((i >= thres\n",
    "                   for i in self.overlaps), dtype=float)) / self.count\n",
    "            for thres in self.Xaxis\n",
    "        ]\n",
    "        \n",
    "    \n",
    "        return np.array(succ)\n",
    "\n",
    "    @property\n",
    "    def average(self):\n",
    "        if len(self.overlaps) == 0:\n",
    "            return 0\n",
    "        return np.trapz(self.value, x=self.Xaxis) * 100 / self.max_overlap\n",
    "\n",
    "\n",
    "class Sequence_t(object):\n",
    "\n",
    "    def __init__(self, name: str, dataset='/data1/yjy/rgbd_benchmark/alldata/'):\n",
    "        self._name = name\n",
    "        self._dataset = dataset\n",
    "        self._path = self._dataset + self._name\n",
    "        self._numframe = self.num_frame\n",
    "\n",
    "    @property\n",
    "    def num_frame(self):\n",
    "        seq_list = os.listdir(os.path.join(self._path, 'color'))\n",
    "        return len(seq_list)\n",
    "    @property\n",
    "    def name(self) -> str:\n",
    "        return self._name\n",
    "\n",
    "    @property\n",
    "    def identifier(self) -> str:\n",
    "        return self._name\n",
    "\n",
    "    @property\n",
    "    def dataset(self):\n",
    "        return self._dataset\n",
    "\n",
    "    @property\n",
    "    def gt(self):\n",
    "        gtfile = os.path.join(self._path, 'groundtruth.txt')\n",
    "        with open(gtfile, 'r') as f:\n",
    "            value = np.loadtxt(f, delimiter=',')\n",
    "        \n",
    "        return value \n",
    "    @property\n",
    "    def invisible(self):\n",
    "        full_occlusion = os.path.join(self._path, 'full-occlusion.tag')\n",
    "        if not os.path.exists(full_occlusion):\n",
    "            value = np.array([0 for i in range(self._numframe)])\n",
    "        else:\n",
    "            with open(full_occlusion, 'r') as f:\n",
    "                value = np.loadtxt(f)\n",
    "        return value\n",
    "\n",
    "class Tracking(object):\n",
    "    def __init__(self, name: str, path='/data1/yjy/rgbd_benchmark/all_benchmark/results'):\n",
    "        self._name = name\n",
    "        self._path = os.path.join(path, self._name) \n",
    "        self._prre = PrRe()\n",
    "        self._seqlist = self.re_list()\n",
    "        self._numseq = len(self._seqlist)\n",
    "        self._lackseq = [] \n",
    "        \n",
    "    @property\n",
    "    def name(self) -> str:\n",
    "        return self._name + '_' + self._path.split('/')[-3]\n",
    "    @property\n",
    "    def prre(self):\n",
    "        return self._prre\n",
    "    def lack(self, seq):\n",
    "        self._lackseq.append(seq)\n",
    "    def re_list(self):\n",
    "        seq_list = []\n",
    "        all_list = os.listdir(os.path.join(self._path, 'rgbd-unsupervised'))\n",
    "        # for name in all_list:\n",
    "        #     if '_001.txt' in name:\n",
    "        #         seq = name.split('_001.txt')[0]\n",
    "        #         seq_list.append(seq)\n",
    "        return all_list\n",
    "\n",
    "    def prebox_conf(self, sequence):\n",
    "        sequence_dir = os.path.join(self._path, 'rgbd-unsupervised', sequence)\n",
    "        boxtxt = os.path.join(sequence_dir, '{}_001.txt'.format(sequence))\n",
    "        try:\n",
    "            with open(boxtxt, 'r') as f:\n",
    "                pre_value = np.loadtxt(f, delimiter=',', skiprows=1)\n",
    "        except:\n",
    "            logging.debug('use \\ t in {}'.format(self._name))\n",
    "            with open(boxtxt, 'r') as f:\n",
    "                pre_value = np.loadtxt(f, delimiter='\\t', skiprows=1)\n",
    "        conftxt = os.path.join(sequence_dir, '{}_001_confidence.value'.format(sequence))\n",
    "        if not os.path.exists(conftxt):\n",
    "            conftxt = os.path.join(sequence_dir, '{}_001_confidence.txt'.format(sequence))\n",
    "        \n",
    "        if not os.path.exists(conftxt):\n",
    "           confidence = [1 for i in range(len(pre_value))]\n",
    "        else:\n",
    "            with open(conftxt, 'r') as f:\n",
    "                confidence = np.loadtxt(f, skiprows=1)\n",
    "        return pre_value, confidence\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 precision and recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrRe(object):\n",
    "    \"\"\"Computes and stores the Success\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "        self.thresholds = np.linspace(1, 0, 100)\n",
    "    def reset(self):\n",
    "        self.overlaps = []\n",
    "        self.confidence = []\n",
    "        self.visible = []\n",
    "\n",
    "    def add_overlap(self, val):\n",
    "        self.overlaps.append(val)\n",
    "\n",
    "    def add_list_iou(self, overlap:list):\n",
    "        self.overlaps = np.concatenate((self.overlaps, overlap))\n",
    "    \n",
    "    def add_confidence(self, confidence:list):\n",
    "        self.confidence = np.concatenate((self.confidence, confidence))\n",
    "    def add_visible(self, visible:list):\n",
    "        self.visible = np.concatenate((self.visible, visible))\n",
    "\n",
    "    @property\n",
    "    def count(self):\n",
    "        return len(self.overlaps)\n",
    "\n",
    "    @property\n",
    "    def value(self):\n",
    "\n",
    "        # succ = [\n",
    "        #     np.sum(np.fromiter((i >= thres\n",
    "        #            for i in self.overlaps), dtype=float)) / self.count\n",
    "        #     for thres in self.Xaxis\n",
    "        # ]\n",
    "        # return np.array(succ)\n",
    "        \n",
    "        n_visible = len([vis for vis in self.visible if vis == True])\n",
    "        precision = len(self.thresholds) * [float(0)]\n",
    "        recall = len(self.thresholds) * [float(0)]\n",
    "\n",
    "        for i, threshold in enumerate(self.thresholds):\n",
    "\n",
    "            subset = self.confidence >= threshold\n",
    "            \n",
    "            if np.sum(subset) == 0:\n",
    "                precision[i] = 1\n",
    "                recall[i] = 0\n",
    "            else:\n",
    "                try:\n",
    "                    # precision[i] = np.mean(self.overlaps[subset])\n",
    "                    precision[i] = np.mean(self.overlaps[subset])\n",
    "                    recall[i] = np.sum(self.overlaps[subset]) / n_visible\n",
    "                except:\n",
    "                    print('exception')\n",
    "                if precision[i] == np.nan or recall[i] == np.nan:\n",
    "                    print('nan')\n",
    "        return precision, recall\n",
    "\n",
    "    @property\n",
    "    def fscore(self):\n",
    "        pr, re = self.value\n",
    "\n",
    "        pr_score = abs(np.trapz(pr, self.thresholds))\n",
    "        re_score = abs(np.trapz(re, self.thresholds))\n",
    "        # pr_score = np.sum(pr)/100\n",
    "        # re_score = np.sum(re)/100\n",
    "        fscore = 2*pr_score*re_score/(pr_score+re_score)\n",
    "        return pr_score, re_score, fscore\n",
    "        \n",
    "class Recall(object):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "def compute_tpr_curves(trajectory: Tracking, sequence: Sequence_t, all_prre: PrRe):\n",
    "    \n",
    "    #overlaps = np.array(calculate_overlaps(trajectory, sequence.groundtruth(), (sequence.size) if bounded else None))\n",
    "    prebbox, confidence = trajectory.prebox_conf(sequence.name)\n",
    "    gt = sequence.gt \n",
    "\n",
    "    # firstframe in each sequence\n",
    "    overlaps = np.concatenate(([1], np.array([estimateIOU(prebbox[i], gt[i+1] ) for i in range(len(prebbox))])))\n",
    "\n",
    "    confidence = np.concatenate(([1], np.array(confidence)))\n",
    "\n",
    "\n",
    "    #n_visible = len([region for region in sequence.groundtruth() if region.type is not RegionType.SPECIAL])\n",
    "    # sequence.invisible (full-occlusion tag) if invisible= 1 full-occlusion invisible\n",
    "    visible = np.array(sequence.invisible) < 1\n",
    "    visible = visible + 0\n",
    "    try:\n",
    "        assert len(overlaps) == len(visible) == len(confidence)\n",
    "    except:\n",
    "        print(\"assert not equal\")    \n",
    "    all_prre.add_list_iou(overlaps)\n",
    "    all_prre.add_visible(visible)\n",
    "    all_prre.add_confidence(confidence) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 analysis of temporal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_results = '/data1/yjy/rgbd_benchmark/all_benchmark/normal/results'\n",
    "seq_list = os.listdir('/data1/yjy/rgbd_benchmark/alldata')\n",
    "seq_list.remove('list.txt')\n",
    "sre_workspace = '/data1/yjy/rgbd_benchmark/all_benchmark/SRE_workspace/'\n",
    "all_robust = [os.path.join(sre_workspace,sre) for sre in os.listdir(sre_workspace)]\n",
    "all_trackers = []\n",
    "origin_trackers = [Tracking(tracker, path=normal_results) for tracker in normal_results] \n",
    "all_trackers.extend(origin_trackers)\n",
    "for robust in all_robust:\n",
    "    trackers = [Tracking(tracker, path=os.path.join(robust, 'results')) for tracker in os.listdir(os.path.join(robust, 'results'))] \n",
    "    all_trackers.extend(trackers)\n",
    "# all_trackers = [Tracking(tracker,path=os.path.join()) for tracker in os.listdir('/data1/yjy/rgbd_benchmark/all_benchmark/SRE_workspace/')]\n",
    "all_sequence = [Sequence_t(seq) for seq in seq_list]\n",
    "\n",
    "for trackers in all_trackers:\n",
    "    print(trackers.name)\n",
    "    if not trackers._name == 'TSDM':\n",
    "        continue \n",
    "    for sequence in all_sequence:\n",
    "        \n",
    "        if sequence.name in trackers._seqlist:\n",
    "            compute_tpr_curves(trackers, sequence, trackers._prre)\n",
    "            #print('{}: length of iou {} '.format(trackers.name, trackers._prre.count))\n",
    "        else:\n",
    "            trackers.lack(sequence.name)\n",
    "            continue\n",
    "    \n",
    "    pr,re,fscore = trackers._prre.fscore\n",
    "    print('Trackers: {}  Seq_num: {} frame_num: {}  pr: {}  re: {}  fscore: {}'.format(trackers.name, trackers._numseq, trackers._prre.count, pr, re, fscore))\n",
    "    logging.info('Trackers: {}  Seq_num: {} frame_num: {}  pr: {}  re: {}  fscore: {}'.format(trackers.name, trackers._numseq, trackers._prre.count, pr, re, fscore))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 read full-occlusion tag "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Siam_LTD_sre1\n",
      "TSDM_sre1\n",
      "Trackers: TSDM_sre1  Seq_num: 171 frame_num: 188710  pr: 0.4646910323075539  re: 0.43620599199470506  fscore: 0.44999818458885726\n",
      "DDiMP_sre1\n",
      "TSDM_sre4\n",
      "Trackers: TSDM_sre4  Seq_num: 171 frame_num: 188710  pr: 0.463644771891277  re: 0.4365822121522031  fscore: 0.44970671564610787\n",
      "DDiMP_sre4\n",
      "TSDM_sre2\n",
      "Trackers: TSDM_sre2  Seq_num: 171 frame_num: 188710  pr: 0.47442429918225754  re: 0.44926423582489805  fscore: 0.4615016039518745\n",
      "DDiMP_sre2\n",
      "Siam_LTD_sre3\n",
      "TSDM_sre3\n",
      "Trackers: TSDM_sre3  Seq_num: 171 frame_num: 188710  pr: 0.4612715525879103  re: 0.42620253364772964  fscore: 0.44304415748403025\n",
      "TSDM_sre6\n",
      "Trackers: TSDM_sre6  Seq_num: 171 frame_num: 188710  pr: 0.444246149177708  re: 0.4210489389419731  fscore: 0.4323366035667597\n",
      "DDiMP_sre6\n",
      "Siam_LTD_sre5\n",
      "TSDM_sre5\n",
      "Trackers: TSDM_sre5  Seq_num: 171 frame_num: 188710  pr: 0.4416310165831166  re: 0.41227174581113146  fscore: 0.4264466593375496\n",
      "DDiMP_sre5\n",
      "TSDM_sre7\n",
      "Trackers: TSDM_sre7  Seq_num: 171 frame_num: 188710  pr: 0.44533592332208205  re: 0.4155090748821913  fscore: 0.4299057737394337\n",
      "DDiMP_sre7\n",
      "Siam_LTD_sre8\n",
      "TSDM_sre8\n",
      "Trackers: TSDM_sre8  Seq_num: 171 frame_num: 188710  pr: 0.45669297971211364  re: 0.4327425121900024  fscore: 0.44439528024120595\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "normal_results = '/data1/yjy/rgbd_benchmark/all_benchmark/normal/results'\n",
    "seq_list = os.listdir('/data1/yjy/rgbd_benchmark/alldata')\n",
    "seq_list.remove('list.txt')\n",
    "sre_workspace = '/data1/yjy/rgbd_benchmark/all_benchmark/SRE_workspace/'\n",
    "all_robust = [os.path.join(sre_workspace,sre) for sre in os.listdir(sre_workspace)]\n",
    "all_trackers = []\n",
    "origin_trackers = [Tracking(tracker, path=normal_results) for tracker in normal_results] \n",
    "all_trackers.extend(origin_trackers)\n",
    "for robust in all_robust:\n",
    "    trackers = [Tracking(tracker, path=os.path.join(robust, 'results')) for tracker in os.listdir(os.path.join(robust, 'results'))] \n",
    "    all_trackers.extend(trackers)\n",
    "# all_trackers = [Tracking(tracker,path=os.path.join()) for tracker in os.listdir('/data1/yjy/rgbd_benchmark/all_benchmark/SRE_workspace/')]\n",
    "all_sequence = [Sequence_t(seq) for seq in seq_list]\n",
    "\n",
    "for trackers in all_trackers:\n",
    "    print(trackers.name)\n",
    "    if not trackers._name == 'TSDM':\n",
    "        continue \n",
    "    for sequence in all_sequence:\n",
    "        \n",
    "        if sequence.name in trackers._seqlist:\n",
    "            compute_tpr_curves(trackers, sequence, trackers._prre)\n",
    "            #print('{}: length of iou {} '.format(trackers.name, trackers._prre.count))\n",
    "        else:\n",
    "            trackers.lack(sequence.name)\n",
    "            continue\n",
    "    \n",
    "    pr,re,fscore = trackers._prre.fscore\n",
    "    print('Trackers: {}  Seq_num: {} frame_num: {}  pr: {}  re: {}  fscore: {}'.format(trackers.name, trackers._numseq, trackers._prre.count, pr, re, fscore))\n",
    "    logging.info('Trackers: {}  Seq_num: {} frame_num: {}  pr: {}  re: {}  fscore: {}'.format(trackers.name, trackers._numseq, trackers._prre.count, pr, re, fscore))\n",
    "\n",
    "\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: container_room_noocc_1, frame: 1644\n"
     ]
    }
   ],
   "source": [
    "print('name: {}, frame: {}'.format(all_sequence[1].name, all_sequence[1]._numframe))\n",
    "# prebbox, confidence = all_trackers[2].prebox_conf(all_sequence[2].name)\n",
    "# for trackers in all_trackers:\n",
    "\n",
    "#     print('name: {} \\t \\t number of seq {} '.format(trackers.name, trackers._numseq))     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2 read confidence score and tracking result (s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## calculate auc of iou "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_35807/2209188759.py:76: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  np.sum(i >= thres\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATCAIS19 iou auc: 66.43529551954242\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# tracker_name = ['DDiMP', 'ATCAIS', 'DRefine', 'SLMD', 'Siam_LTD', 'TSDM', 'iiau_rgbd']\n",
    "tracker_name = ['ATCAIS19']\n",
    "gt_dir = '/data1/yjy/rgbd_benchmark/stc_benchmark/RGBDdataset/'\n",
    "su = Success()\n",
    "for tracker in tracker_name:\n",
    "    su.reset()\n",
    "    tracking_result_dir = '/home/yangjinyu/rgbd_tracker/benchmark_workspace/stc_workspace/results/{}/rgbd-unsupervised'.format(tracker)\n",
    "    seqlist = os.listdir(tracking_result_dir)\n",
    "    for seq in seqlist:\n",
    "        gt_seq = os.path.join(gt_dir, seq, 'groundtruth.txt' )\n",
    "        pre_seq = os.path.join(tracking_result_dir, '{}/{}_001.txt'.format(seq, seq))\n",
    "        with open(gt_seq, 'r') as f:\n",
    "            gt_value = np.loadtxt(f, delimiter=',', skiprows=1)\n",
    "        with open(pre_seq, 'r') as f:\n",
    "            pre_value = np.loadtxt(f, delimiter=',', skiprows=1)\n",
    "        if not len(gt_value) == len(pre_value):\n",
    "            raise TypeError\n",
    "        for i in range(len(gt_value)):\n",
    "            iou = estimateIOU(gt_value[i], pre_value[i])\n",
    "            su.add_overlap(iou)\n",
    "    print('{} iou auc: {}'.format(tracker, su.average))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### stc tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stc iou auc: 39.79200786112021\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# tracker_name = ['DDiMP', 'ATCAIS', 'DRefine', 'SLMD', 'Siam_LTD', 'TSDM', 'iiau_rgbd']\n",
    "tracker_name = ['stc']\n",
    "gt_dir = '/data1/yjy/rgbd_benchmark/stc_benchmark/RGBDdataset/'\n",
    "su = Success()\n",
    "for tracker in tracker_name:\n",
    "    su.reset()\n",
    "    tracking_result_dir = '/home/yangjinyu/rgbd_tracker/benchmark_workspace/stc_workspace/results/{}/rgbd-unsupervised'.format(tracker)\n",
    "    seqlist = os.listdir(tracking_result_dir)\n",
    "    for seqtxt in seqlist:\n",
    "        gt_seq = os.path.join(gt_dir, seqtxt.split('.')[0], 'groundtruth.txt' )\n",
    "        pre_seq = os.path.join(tracking_result_dir, seqtxt)\n",
    "        with open(gt_seq, 'r') as f:\n",
    "            gt_value = np.loadtxt(f, delimiter=',', skiprows=1)\n",
    "        with open(pre_seq, 'r') as f:\n",
    "            pre_value = np.loadtxt(f, delimiter=',', skiprows=1)\n",
    "        if not len(gt_value) == len(pre_value):\n",
    "            raise TypeError\n",
    "        for i in range(len(gt_value)):\n",
    "            iou = estimateIOU(gt_value[i], pre_value[i])\n",
    "            su.add_overlap(iou)\n",
    "    print('{} iou auc: {}'.format(tracker, su.average))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### copy result to all_benchmark"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5d961e761471cb2a6ecd0e717f761ad980996fff136378d2cdef2349e503c6df"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('nb_conda': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
